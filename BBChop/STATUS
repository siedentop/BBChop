Copyright 2008 Ealdwulf Wuffinga


Robustness (my estimate of):

Well tested:
  dag.py
  evidence.py
  likelihood.py
  BBChop.py

Only casual testing so far:
  bbchop       - ie, the main driver program. 
  dagRead.py
  testLog.py
  listUtils.py (although it's well exercized by the testing of the math modules)
  
Doesn't need much testing:
  entropy.py   - Derived from standard references
  miscMath.py  - Derived from standard references, except test-only functions 
  numberType.py   - is a simple wrapper



Questions:

- curiously, multirate gives poor results when tested with a singlerate simulation, whereas one
  might expect it to be more conservative. I think this is another case where expecting a bayesian method to 
  be 'conservative' is a mistake: you must give it the *right* prior; there is no 'more conservative'
  prior.

- precision 

Due to the calculation of probabilities by normalising likelihoods, we have to use high precision
math (mpmath) to avoid divide by zero when numbers get too small for 'doubles'.


The problem is the Beta function. In bbchop it is always passed D and T where D is 
the sum of the number of detecting observations in some of the revisions, and T is the 
same for nondetecting observations. Beta(x,y) underflows a python float 
if both x and y are > ~550, and also in other cases when one is smaller and the other, 
larger. BBChop never looks again at a revision if the bug has been observed there, but if 
there are a large number of revisions, it might look at enough of them to cause a problem.

Obviously no-one is going to manually do hundreds of observations, but  I want BBChop 
to work in the case where someone runs it on a machine in the corner for a few days,
or even weeks,  to track down a bug which occurs too infrequently to bisect manually. 


- cost

What is the actual search cost (in looks) for different N and different fault
locs? Suspect it gets worse when loc is near the end.


- testing. Is there a better way to test? Can we test probs() directly?

Could use importance sampling to vary the calculation an bit.



TODO:



- finish paper.

- for paper: compare agains naive strategy of binary chop with N obs at each location: plot
  graph of obs vs P(correct answer) for various N with naive method, and for various C with 
  entropy method.


- reduce dag.py from 0(N^2) to O(N) in more cases (in particular, when the dag contains both 
 dominating and antidominating nodes, which will usually be the case)

 - Driver program:
   - cannot specifiy priors with dag. How to fix? Could require identifiers in prior file, or 
     add priors to dag file?
   - should log by default (to fixed filename -  bbchop.log?)

- produce distribution graphs for greedyStrat and nearlyGreedyStrat

- abstract out termination condition?
  - termination by utility?
- test for 'skipping'

- maybe use http://www.cs.berkeley.edu/~fateman/papers/factorial.pdf



Done:
   - add parsing of dag
   - logging and restarting from log
   - add option to read in priors
   - add option to call script to switch even when decisions are manual
   - added support for strategies. Implemented 'nearlyGreedy' strategy.
   - add likelihood function for deterministic tests.
   - add option to read 'version numbers' from a file, and display then instead of location numbers
   - test support for generalised history (DAG)


O(N) version of Entropies() using renyi entropy.


---


 Probability calculation: there is a question over whether to include choice(n,k) in
the equation for 'g'. 

Decided to leave it out, on the grounds that we expect to know the order. It
makes no difference unless you detect at the same point more than once, anyway.


--

 search strategy.

There was a fixme in entropies() regarding a -1. decide whether it it cleaner to
have this in or out. [decided to leave it out]

The issue is whether we want to define the last location as being one which we
already know to have the fault, or not. Not, means we can't initially observe
the known-faulty location in order to improve out knowlege of R, if this is a good
long term strategy. 




